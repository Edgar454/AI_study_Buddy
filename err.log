/root/.local/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.
  warn(
/root/.local/lib/python3.11/site-packages/passlib/utils/__init__.py:854: DeprecationWarning: 'crypt' is deprecated and slated for removal in Python 3.13
  from crypt import crypt as _crypt
/root/.local/lib/python3.11/site-packages/celery/platforms.py:841: SecurityWarning: You're running the worker with superuser privileges: this is
absolutely not recommended!

Please specify a different user using the --uid option.

User information: uid=0 euid=0 gid=0 egid=0

  warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
[2025-05-07 07:10:33,826: INFO/MainProcess] Connected to redis://redis:6379/0
[2025-05-07 07:10:33,833: INFO/MainProcess] mingle: searching for neighbors
[2025-05-07 07:10:33,851: WARNING/MainProcess] /root/.local/lib/python3.11/site-packages/kombu/transport/redis.py:514: DeprecationWarning: Call to 'get_connection' function with deprecated usage of input argument/s '['command_name']'. (Use get_connection() without args instead) -- Deprecated since version 5.3.0.
  client.connection = client.connection_pool.get_connection('_')

[2025-05-07 07:10:34,875: INFO/MainProcess] mingle: all alone
[2025-05-07 07:10:34,920: INFO/MainProcess] celery@4a69253a7ca5 ready.
[2025-05-07 07:12:48,688: INFO/MainProcess] Task src.celery_app.process_file_task[2d3f3fec-eef4-47e7-a286-b2ef5a9250b5] received
[2025-05-07 07:12:49,975: WARNING/ForkPoolWorker-1] File 91f6d0a5091461ccc94795fc13a85427f56959850db35e898bee4e06e0286d59 not found in cache. Processing...
[2025-05-07 07:12:50,799: WARNING/ForkPoolWorker-1] ğŸ–‡ AgentOps: [34mSession Replay: https://app.agentops.ai/sessions?trace_id=97ef5a5a7215205ba6f5451ab9c4450e[0m
[2025-05-07 07:12:50,806: WARNING/ForkPoolWorker-1] â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Execution Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                              â”‚
â”‚  Crew Execution Started                                                      â”‚
â”‚  Name: crew                                                                  â”‚
â”‚  ID: 3eddbcf1-77c4-4060-8e9d-bb0cf6a7f9d5                                    â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[2025-05-07 07:12:52,498: WARNING/ForkPoolWorker-1] ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: d06e3dbe-1412-4822-a3bb-133b7215da38
       Status: Executing Task...
[2025-05-07 07:12:52,505: WARNING/ForkPoolWorker-1] ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: d06e3dbe-1412-4822-a3bb-133b7215da38
       Status: Executing Task...
    â””â”€â”€ ğŸ¤– Agent: Specialiste de la recherche
        
            Status: In Progress
[2025-05-07 07:12:52,506: WARNING/ForkPoolWorker-1] [1m[95m# Agent:[00m [1m[92mSpecialiste de la recherche[00m
[2025-05-07 07:12:52,506: WARNING/ForkPoolWorker-1] [95m## Task:[00m [92mAnalysez le matÃ©riel Ã©ducatif fourni par l'utilisateur : /tmp/tmp39amhs3z/sT0-Obedience-Checklist.pdf, et transformez-le en un contenu enrichi et structurÃ© pour une utilisation ultÃ©rieure : 1. Extraire et organiser les sections principales, idÃ©es clÃ©s, et concepts importants du matÃ©riel d'Ã©tude. 2. ComplÃ©ter les idÃ©es principales en effectuant des recherches supplÃ©mentaires (par ex., via des outils comme Serper) pour fournir des exemples, des analogies ou des donnÃ©es pertinentes. 3. Enrichissez le contenu extrait avec des exemples concrets, des applications pratiques et des informations supplÃ©mentaires grÃ¢ce Ã  des recherches complÃ©mentaires. 4. GÃ©nÃ©rer un document final structurÃ© et clair qui rÃ©sume les idÃ©es clÃ©s tout en ajoutant des informations complÃ©mentaires. 5. Assurez-vous que la sortie soit adaptÃ©e pour une exploration approfondie et facilement rÃ©utilisable par d'autres agents ou utilisateurs.
[00m
[2025-05-07 07:12:52,508: WARNING/ForkPoolWorker-1] ğŸ¤– Agent: Specialiste de la recherche

    Status: In Progress
â””â”€â”€ ğŸ§  Thinking...
[92m07:12:52 - LiteLLM:INFO[0m: utils.py:3100 - 
LiteLLM completion() model= hf:mistralai/Mixtral-8x22B-Instruct-v0.1; provider = openai
[2025-05-07 07:12:52,532: INFO/ForkPoolWorker-1] 
LiteLLM completion() model= hf:mistralai/Mixtral-8x22B-Instruct-v0.1; provider = openai
[2025-05-07 07:12:54,982: INFO/ForkPoolWorker-1] HTTP Request: POST https://api.glhf.chat/v1/chat/completions "HTTP/1.1 200 OK"
[92m07:12:55 - LiteLLM:INFO[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler
[2025-05-07 07:12:55,010: INFO/ForkPoolWorker-1] Wrapper: Completed Call, calling success_handler
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,011: INFO/ForkPoolWorker-1] selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,012: INFO/ForkPoolWorker-1] selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,013: INFO/ForkPoolWorker-1] selected model name for cost calculation: hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,013: INFO/ForkPoolWorker-1] selected model name for cost calculation: openai/hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,265: WARNING/ForkPoolWorker-1] ğŸ¤– Agent: Specialiste de la recherche

    Status: In Progress
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,266: INFO/ForkPoolWorker-1] selected model name for cost calculation: openai/mistralai/Mixtral-8x22B-Instruct-v0.1
[92m07:12:55 - LiteLLM:INFO[0m: cost_calculator.py:636 - selected model name for cost calculation: hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,270: INFO/ForkPoolWorker-1] selected model name for cost calculation: hf:mistralai/Mixtral-8x22B-Instruct-v0.1
[2025-05-07 07:12:55,290: WARNING/ForkPoolWorker-1] ğŸ¤– Agent: Specialiste de la recherche

    Status: In Progress
[2025-05-07 07:12:55,461: WARNING/ForkPoolWorker-1] 

[1m[95m# Agent:[00m [1m[92mSpecialiste de la recherche[00m
[2025-05-07 07:12:55,462: WARNING/ForkPoolWorker-1] [95m## Thought:[00m [92mI need to analyze the educational material provided by the user, extract the main sections and key ideas, and conduct additional research to enrich the content. I will start by using the PDF reading tool to read the content of the study material located at /tmp/tmp39amhs3z/sT0-Obedience-Checklist.pdf.[00m
[2025-05-07 07:12:55,462: WARNING/ForkPoolWorker-1] [95m## Using tool:[00m [92mPDF reading tool[00m
[2025-05-07 07:12:55,462: WARNING/ForkPoolWorker-1] [95m## Tool Input:[00m [92m
"{\"path\": \"/tmp/tmp39amhs3z/sT0-Obedience-Checklist.pdf\"}"[00m
[2025-05-07 07:12:55,462: WARNING/ForkPoolWorker-1] [95m## Tool Output:[00m [92m
Ok slave, youâ€™ve listened to the brainwashing file and youâ€™re eager to know what 
comes next. Thatâ€™s great because eagerness creates ease and helps you take the 
right next steps. 
Here are some things you can do to serve & obey the Academy while you 
brainwash yourself in preparation for the next level of slave training.  
MOST IMPORTANT:
 
	 Listen	to	the	brainwashing	file	as	much	as	possible.	
  Keep listening, slave. Listen until the next level of slave training is made 
available to you, and then keep listening after that. The more you listen, the 
deeper you go.
ONE OFFS:
 	 Give	us	your	feedback	(Lesson	3	in	your	training.)
 	 Put	GsA	in	your	online	profiles	(Recon,	Grindr,	Scruff,	Growlr,	etc)
  you may put â€œslave is enrolled in training @GayslaveAcademyâ€ to signal to 
Men that you are serious about being a good slave.
 	 Follow	us	on	Twitter	@gayslaveacademy .
  If you donâ€™t have a Twitter account yet, make one. 
 	 Tweet	a	special	picture	of	yourself	and	tag	us	in	it.
  Let us show the world what a good boy you are: Tweet a picture with â€œGay 
slave Academyâ€ written on or near your body and tag  
@gayslaveacademy so we can retweet your pic.
ONGOING:
 
 Spread	the	word.	Tell	other	subs	(and	their	Masters)	about	GsA.
 
 Retweet	our	posts	on	Twitter!
THE SERVE & OBEY CHECKLIST
Move to the head of the class  
& prepare yourself for the next 
level of slave trainingâ€¦
Â© 2021 Gay slave Academy â€¢ www.gayslaveacademy.com[00m
[2025-05-07 07:12:55,463: WARNING/ForkPoolWorker-1] ğŸ¤– Agent: Specialiste de la recherche

    Status: In Progress
â””â”€â”€ ğŸ§  Thinking...
[92m07:12:55 - LiteLLM:INFO[0m: utils.py:3100 - 
LiteLLM completion() model= hf:mistralai/Mixtral-8x22B-Instruct-v0.1; provider = openai
[2025-05-07 07:12:55,464: INFO/ForkPoolWorker-1] 
LiteLLM completion() model= hf:mistralai/Mixtral-8x22B-Instruct-v0.1; provider = openai
[2025-05-07 07:12:56,262: INFO/ForkPoolWorker-1] HTTP Request: POST https://api.glhf.chat/v1/chat/completions "HTTP/1.1 400 Bad Request"
[2025-05-07 07:12:56,266: WARNING/ForkPoolWorker-1] LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.
[2025-05-07 07:12:56,267: WARNING/ForkPoolWorker-1] [1;31mProvider List: https://docs.litellm.ai/docs/providers[0m
[2025-05-07 07:12:56,633: WARNING/ForkPoolWorker-1] ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: d06e3dbe-1412-4822-a3bb-133b7215da38
       Status: Executing Task...
    â””â”€â”€ ğŸ¤– Agent: Specialiste de la recherche
        
            Status: In Progress
        â””â”€â”€ âŒ LLM Failed
[2025-05-07 07:12:56,636: WARNING/ForkPoolWorker-1] â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM Error â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                              â”‚
â”‚  âŒ LLM Call Failed                                                          â”‚
â”‚  Error: litellm.BadRequestError: OpenAIException - Error code: 400 -         â”‚
â”‚  {'error': 'Error from inference backend: 400 Input validation error'}       â”‚
â”‚                                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[2025-05-07 07:12:56,636: ERROR/ForkPoolWorker-1] LiteLLM call failed: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}
[2025-05-07 07:12:56,638: WARNING/ForkPoolWorker-1] [31;1mğŸ–‡ AgentOps: Error in trace creation: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[0m
[2025-05-07 07:12:56,716: WARNING/ForkPoolWorker-1] [91m Error during LLM call: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[00m
[2025-05-07 07:12:56,717: WARNING/ForkPoolWorker-1] [91m An unknown error occurred. Please check the details below.[00m
[2025-05-07 07:12:56,718: WARNING/ForkPoolWorker-1] [91m Error details: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[00m
[2025-05-07 07:12:56,721: WARNING/ForkPoolWorker-1] [31;1mğŸ–‡ AgentOps: Error in trace creation: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[0m
[2025-05-07 07:12:56,798: WARNING/ForkPoolWorker-1] ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: d06e3dbe-1412-4822-a3bb-133b7215da38
       Assigned to: Specialiste de la recherche
    
       Status: âŒ Failed
    â””â”€â”€ ğŸ¤– Agent: Specialiste de la recherche
        
            Status: In Progress
        â””â”€â”€ âŒ LLM Failed
[2025-05-07 07:12:56,803: WARNING/ForkPoolWorker-1] â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                              â”‚
â”‚  Task Failed                                                                 â”‚
â”‚  Name: d06e3dbe-1412-4822-a3bb-133b7215da38                                  â”‚
â”‚  Agent: Specialiste de la recherche                                          â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[2025-05-07 07:12:56,805: WARNING/ForkPoolWorker-1] [31;1mğŸ–‡ AgentOps: Error in trace creation: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[0m
[2025-05-07 07:12:56,843: WARNING/ForkPoolWorker-1] â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                              â”‚
â”‚  Crew Execution Failed                                                       â”‚
â”‚  Name: crew                                                                  â”‚
â”‚  ID: 3eddbcf1-77c4-4060-8e9d-bb0cf6a7f9d5                                    â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[2025-05-07 07:12:56,844: WARNING/ForkPoolWorker-1] [31;1mğŸ–‡ AgentOps: Error in trace creation: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}[0m
[2025-05-07 07:12:56,874: WARNING/ForkPoolWorker-1] ğŸ–‡ AgentOps: [34mSession Replay: https://app.agentops.ai/sessions?trace_id=97ef5a5a7215205ba6f5451ab9c4450e[0m
[2025-05-07 07:12:57,342: WARNING/ForkPoolWorker-1] [31;1mğŸ–‡ AgentOps: [agentops.InternalSpanProcessor] Error uploading logfile: Upload failed: 502[0m
[2025-05-07 07:12:57,344: WARNING/ForkPoolWorker-1] An error occurred: Error processing material: litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': 'Error from inference backend: 400 Input validation error'}
[2025-05-07 07:12:57,817: WARNING/ForkPoolWorker-1] Notification sent successfully: 200
[2025-05-07 07:12:57,818: INFO/ForkPoolWorker-1] Task src.celery_app.process_file_task[2d3f3fec-eef4-47e7-a286-b2ef5a9250b5] succeeded in 7.5145976550011255s: {'error': 'Error processing material: litellm.BadRequestError: OpenAIException - Error code: 400 - {\'error\': \'Error from inference backend: 400 Input validation error\'}'}
